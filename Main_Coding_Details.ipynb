{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Coding Details",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zLolz-ZK/skin-cancer-detection-website/blob/main/Main_Coding_Details.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQpMbdi6Xikr"
      },
      "source": [
        "#Importing the Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueFJnE6I559p"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uktJn4L1XuKL"
      },
      "source": [
        "#Installing Kaggle and downloading the dataset from the api token key stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv1b9YTSX2BC"
      },
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp 'drive/MyDrive/Cancer Model/kaggle.json' ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list\n",
        "!mkdir training\n",
        "!cd training\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgFV1UdXYPGI"
      },
      "source": [
        "#Unzipping the dataset and Extracting the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4NPwEFfSMbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fcbe4f-52f1-4fed-8452-e46e4dd1e645"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name='skin-cancer-mnist-ham10000.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zipx:\n",
        "  zipx.extractall()\n",
        "  print('finished!!!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFKxfKp8YjX4"
      },
      "source": [
        "#Using Pandas to see the Dataset CSV information and metadata. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsJL9HipJiFZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "37a51bd3-4e60-459d-fbb4-4ed8b2980c7d"
      },
      "source": [
        "df_data = pd.read_csv('HAM10000_metadata.csv')\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqcx-8ltZPPh"
      },
      "source": [
        "#Using Pandas to see the Dataset CSV information and metadata. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "RSnExaJdZPPi",
        "outputId": "37a51bd3-4e60-459d-fbb4-4ed8b2980c7d"
      },
      "source": [
        "df_data = pd.read_csv('HAM10000_metadata.csv')\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1xFbxTdY1O8"
      },
      "source": [
        "#Searching For unique lessions to eliminate duplicate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg4C6upt-KlK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "31dc4c46-5304-4ed7-ea69-25652e6538e5"
      },
      "source": [
        "# identify lession and with lesion_id\n",
        "df = df_data.groupby('lesion_id').count()\n",
        "# filter out lesion_id's that have only one image associated with it\n",
        "df = df[df['image_id'] == 1]\n",
        "df.reset_index(inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0000004</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0000007</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0000008</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id  image_id  dx  dx_type  age  sex  localization\n",
              "0  HAM_0000001         1   1        1    1    1             1\n",
              "1  HAM_0000003         1   1        1    1    1             1\n",
              "2  HAM_0000004         1   1        1    1    1             1\n",
              "3  HAM_0000007         1   1        1    1    1             1\n",
              "4  HAM_0000008         1   1        1    1    1             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFxGep9RZ94o"
      },
      "source": [
        "# this will tell us how many images are associated with each lesion_id\n",
        "df = df_data.groupby('lesion_id').count()\n",
        "# now we filter out lesion_id's that have only one image associated with it\n",
        "df = df[df['image_id'] == 1]\n",
        "df.reset_index(inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFlofzWQS9El",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "29ad5c70-c7f9-4116-a189-c3ac9a6fe8db"
      },
      "source": [
        "def identify_duplicates(x):\n",
        "    \n",
        "    unique_list = list(df['lesion_id'])\n",
        "    if x in unique_list:\n",
        "        return 'no_duplicates'\n",
        "    else:\n",
        "        return 'has_duplicates'\n",
        "    \n",
        "# create a new colum that is a copy of the lesion_id column\n",
        "df_data['duplicates'] = df_data['lesion_id']\n",
        "# apply the function to this new column\n",
        "df_data['duplicates'] = df_data['duplicates'].apply(identify_duplicates)\n",
        "\n",
        "df_data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>duplicates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>has_duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>has_duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>has_duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>has_duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>has_duplicates</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx  ...   sex  localization      duplicates\n",
              "0  HAM_0000118  ISIC_0027419  bkl  ...  male         scalp  has_duplicates\n",
              "1  HAM_0000118  ISIC_0025030  bkl  ...  male         scalp  has_duplicates\n",
              "2  HAM_0002730  ISIC_0026769  bkl  ...  male         scalp  has_duplicates\n",
              "3  HAM_0002730  ISIC_0025661  bkl  ...  male         scalp  has_duplicates\n",
              "4  HAM_0001466  ISIC_0031633  bkl  ...  male           ear  has_duplicates\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoKR91gmB6bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502747ea-1f05-4f55-dc07-ec21c4966a9c"
      },
      "source": [
        "df_data['duplicates'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no_duplicates     5514\n",
              "has_duplicates    4501\n",
              "Name: duplicates, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEf5_l4lB7Lb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c291543-a644-4766-90ad-3997126f19fa"
      },
      "source": [
        "# now we filter out images that don't have duplicates\n",
        "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
        "\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5514, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bps-yvzCAfH"
      },
      "source": [
        "# now we create a test set using df because we are sure that none of these images\n",
        "# have augmented duplicates in the train set\n",
        "\n",
        "y = df['dx']\n",
        "\n",
        "_, df_test = train_test_split(df, test_size=0.20, random_state=101, stratify=y)\n",
        "y = df_test['dx']\n",
        "df_test, df_val = train_test_split(df_test, test_size=0.50, random_state=101, stratify=y)\n",
        "\n",
        "df_test.shape, _.shape,df_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGK4t2ldY-iJ"
      },
      "source": [
        "#Creating Train, Test and Validation Dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS6mKcQoZ2Pn"
      },
      "source": [
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test_dir')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "classes=['nv','mel','bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
        "\n",
        "for cl in classes:\n",
        "    cl = os.path.join(train_dir, cl)\n",
        "    os.mkdir(cl)\n",
        "for cl in classes:\n",
        "    cl = os.path.join(test_dir, cl)\n",
        "    os.mkdir(cl)\n",
        "for cl in classes:\n",
        "    cl = os.path.join(val_dir, cl)\n",
        "    os.mkdir(cl)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcECTIEzY_ar"
      },
      "source": [
        "# Identifying  the train, test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVShkCdBCE6j"
      },
      "source": [
        "#identify test rows val\n",
        "def identify_test_rows(x):\n",
        "    # create a list of all the lesion_id's in the test set\n",
        "    test_list = list(df_test['image_id'])\n",
        "    val_list = list(df_val['image_id'])\n",
        "    if str(x) in test_list:\n",
        "        return 'test'\n",
        "    elif str(x) in val_list:\n",
        "        return 'val'\n",
        "    else:\n",
        "        return 'train'\n",
        "\n",
        "# create a new colum that is a copy of the image_id column\n",
        "df_data['train_test_val'] = df_data['image_id']\n",
        "# apply the function to this new column\n",
        "df_data['train_test_val'] = df_data['train_test_val'].apply(identify_test_rows)\n",
        "   \n",
        "# filter out train rows\n",
        "df_train = df_data[df_data['train_test_val'] == 'train']\n",
        "\n",
        "print(f'{len(df_train)} + {len(df_test)} + {len(df_val)} = {len(df_val)+len(df_test)+len(df_train)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d956r9y1CGHU"
      },
      "source": [
        "df_train['dx'].value_counts()\n",
        "df_test['dx'].value_counts()\n",
        "# Set the image_id as the index in df_data\n",
        "df_data.set_index('image_id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mti5zkSwZHKe"
      },
      "source": [
        "# Transferring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJZAL9DMCZGD"
      },
      "source": [
        "# Get a list of images in each of the two folders test\n",
        "folder_1 = os.listdir('ham10000_images_part_1')\n",
        "folder_2 = os.listdir('ham10000_images_part_2')\n",
        "\n",
        "# Get a list of train and test images\n",
        "train_list = list(df_train['image_id'])\n",
        "test_list = list(df_test['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "for image in train_list:    \n",
        "    fname = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('ham10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Transfer the test images\n",
        "for image in test_list:\n",
        "    fname = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "  \n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('ham10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(test_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(test_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "for image in val_list:\n",
        "    fname = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "    \n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('ham10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('ham10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RymI5w-9iseT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c92f12-90ff-469d-ceee-8b88ca6f299e"
      },
      "source": [
        "def num_of_images(train = '', test = '',val=''):\n",
        "  base = 'base_dir'\n",
        "  test_dir = 'test_dir'\n",
        "  train_dir = 'train_dir'\n",
        "  val_dir = 'val_dir'\n",
        "  print(train_dir if train == 'train' else '', test_dir if test == 'test' else '',val_dir if val == 'val' else '' )\n",
        "  for cl in classes:\n",
        "    \n",
        "    print(\n",
        "        len(os.listdir(os.path.join(base, train_dir, cl))) if train == 'train' else '', \n",
        "        len(os.listdir(os.path.join(base, test_dir, cl))) if test == 'test' else '',\n",
        "        len(os.listdir(os.path.join(base, val_dir, cl))) if val == 'val' else '',\n",
        "          )\n",
        "num_of_images('train','test','val')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dir test_dir val_dir\n",
            "5364 1341 671\n",
            "890 223 112\n",
            "879 220 110\n",
            "411 103 52\n",
            "262 65 32\n",
            "114 28 14\n",
            "92 23 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17VH4EPbk_y"
      },
      "source": [
        "#Setting up the global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY2V83rzDAyE"
      },
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "test_path = 'base_dir/test_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "num_train_samples = len(df_train)\n",
        "num_test_samples = len(df_test)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 32\n",
        "test_batch_size = 32\n",
        "val_batch_size = 32\n",
        "image_size = 299#224,128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZz4q740C6NL",
        "outputId": "73f05aaf-eebd-412e-f77f-2be0845bfa9e"
      },
      "source": [
        "for i in classes:\n",
        "  print(f'{i} train -> {len(os.listdir(\"base_dir/train_dir/\"+f\"{i}\"))}')\n",
        "  print(f'{i} test -> {len(os.listdir(\"base_dir/test_dir/\"+f\"{i}\"))}')\n",
        "  print(f'{i} val -> {len(os.listdir(\"base_dir/val_dir/\"+f\"{i}\"))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nv train -> 5364\n",
            "nv test -> 1341\n",
            "nv val -> 671\n",
            "mel train -> 890\n",
            "mel test -> 223\n",
            "mel val -> 112\n",
            "bkl train -> 879\n",
            "bkl test -> 220\n",
            "bkl val -> 110\n",
            "bcc train -> 411\n",
            "bcc test -> 103\n",
            "bcc val -> 52\n",
            "akiec train -> 262\n",
            "akiec test -> 65\n",
            "akiec val -> 32\n",
            "vasc train -> 114\n",
            "vasc test -> 28\n",
            "vasc val -> 14\n",
            "df train -> 92\n",
            "df test -> 23\n",
            "df val -> 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hNFnqj_bLyx"
      },
      "source": [
        "#Creating Training Examples from augmented dimages to increase amount of training example to reduce overfitting and improve accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_zMdocHjArY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974e396e-d3f6-4eca-e6a4-c5623b512aef"
      },
      "source": [
        "for item in classes:\n",
        "    #classes=['nv','mel','bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
        "    # We are creating temporary directories here because we delete these directories later\n",
        "    # create a base dir\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "    # create a dir within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        " \n",
        "    # Choose a class\n",
        "    img_class = item\n",
        " \n",
        "    # list all images in that directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n",
        "    for fname in img_list:\n",
        "            # source path to image\n",
        "            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "            # destination path to image\n",
        "            dst = os.path.join(img_dir, fname)\n",
        "            # copy the image from the source to the destination\n",
        "            shutil.copyfile(src, dst)\n",
        " \n",
        " \n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        " \n",
        "    # Create a data generator\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        brightness_range=(0.9,1.1),\n",
        "        #fill_mode='bilinear',\n",
        "        #shear_range=0.2,\n",
        "        )\n",
        " \n",
        "    batch_size = 50\n",
        " \n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                           save_to_dir=save_path,\n",
        "                                           save_format='jpg',\n",
        "                                            target_size=(image_size,image_size),\n",
        "                                            batch_size=batch_size)\n",
        " \n",
        " \n",
        " \n",
        "    # Generate the augmented images and add them to the training folders\n",
        "    \n",
        "    ###########\n",
        "    \n",
        "    num_aug_images_wanted = 2000 # total number of images we want to have in each class\n",
        "    \n",
        "    ###########\n",
        "    \n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
        " \n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0,num_batches):\n",
        " \n",
        "        imgs, labels = next(aug_datagen)\n",
        "        \n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6042 images belonging to 1 classes.\n",
            "Found 1079 images belonging to 1 classes.\n",
            "Found 1033 images belonging to 1 classes.\n",
            "Found 488 images belonging to 1 classes.\n",
            "Found 304 images belonging to 1 classes.\n",
            "Found 132 images belonging to 1 classes.\n",
            "Found 109 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flb56RVAZNCS"
      },
      "source": [
        "# Setting up The Image Data Generator for augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EbrlAozDOUL"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "transformation_ratio = .05\n",
        "datagen = ImageDataGenerator(\n",
        "    #rescale=1./255,\n",
        "    preprocessing_function = tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
        "    rotation_range=180,\n",
        "    zoom_range=[0.8,1.2],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=2,#-1,0,1 possible vals\n",
        "    height_shift_range=2,#-1,0,1\n",
        "    brightness_range=(0.9,1.1),\n",
        "    shear_range=0.1,\n",
        "    )\n",
        "\n",
        "train_batches = datagen.flow_from_directory(\n",
        "      train_path,\n",
        "      target_size=(image_size,image_size),\n",
        "      batch_size=train_batch_size,\n",
        "      shuffle = True,\n",
        "      class_mode = 'sparse'\n",
        "      )\n",
        "datagen2 = ImageDataGenerator(\n",
        "    tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
        ")\n",
        "valid_batches = datagen2.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size,image_size),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle = True,\n",
        "    class_mode = 'sparse'\n",
        "    )\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_batches = datagen2.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size = (image_size,image_size),\n",
        "    batch_size = 1,\n",
        "    shuffle = False,\n",
        "    class_mode = 'sparse'\n",
        "    )\n",
        "num_of_images(train='train',test='test',val='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C2gNlZGdUcy"
      },
      "source": [
        "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "        \n",
        "#plots(imgs, titles=None) # titles=labels will display the image labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkKuyUK2DTN8"
      },
      "source": [
        "#Creating the Model\n",
        "#iresnetv2 = iresnetv2.layers[-2].output\n",
        "iresnetv2 = tf.keras.applications.InceptionResNetV2(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(image_size, image_size, 3),\n",
        "    include_top=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcBiwZ_8Ch4G"
      },
      "source": [
        "#iresnetv2.layers.pop()\n",
        "iresnetv2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhFw2vy7s3xL"
      },
      "source": [
        "for i in iresnetv2.layers[:400]:\n",
        "  i.trainable = False\n",
        "for i in iresnetv2.layers[400:]:\n",
        "  #if isinstance(i,tf.keras.layers.BatchNormalization):\n",
        "  i.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILYsGwb0GJsH"
      },
      "source": [
        "#model 1 acc 70% val accu 81% loss 0.8~0.9\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import  Model\n",
        "model2 = tf.keras.models.Sequential([\n",
        "                                iresnetv2,\n",
        "                                GlobalAveragePooling2D(),\n",
        "                                tf.keras.layers.Flatten(),\n",
        "                                tf.keras.layers.Dense(64,activation='relu'),\n",
        "                                tf.keras.layers.Dropout(0.5),\n",
        "                                tf.keras.layers.Dense(7,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "#model = Model(vgg.input, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6RjuPcFDhm8"
      },
      "source": [
        "model2.compile(optimizer='nadam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['acc']\n",
        "              )\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcSqJSU-UiX5"
      },
      "source": [
        "# Setting up the model parameters and automated supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY2FhSwiHCJx"
      },
      "source": [
        "file_path = os.getcwd()\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "   if epoch%3!=0:\n",
        "     return lr\n",
        "   else:\n",
        "     return lr * 0.9\n",
        "\n",
        "top_weights_path = os.path.join(os.path.abspath(file_path), 'dense_03_06.h5')\n",
        "\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='val_acc',\n",
        "                                        verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=0),\n",
        "    tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0),\n",
        "    \n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHLyrFUqS3oV"
      },
      "source": [
        "epochs  = 40\n",
        "history = model.fit(\n",
        "    train_batches, \n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=valid_batches,\n",
        "    validation_steps=val_steps,\n",
        "    epochs=epochs,\n",
        "     callbacks = callbacks_list \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T3yq7IheTyo"
      },
      "source": [
        "loss, acc = \\\n",
        "model.evaluate(test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es4Eyi8xqNi2"
      },
      "source": [
        "# Fine Training The model to imporove its accuracy by training the extractior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_M_j1pW72UX"
      },
      "source": [
        "l = 100\n",
        "\n",
        "for layer in dense_model.layers[l:]:\n",
        "  if not isinstance(layer, layers.BatchNormalization):\n",
        "    layer.trainable = True\n",
        "top_weights_path = os.path.join(os.path.abspath(file_path), 'dense_model_fine.h5')\n",
        "\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='val_acc',\n",
        "                                        verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=0),\n",
        "    tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDHz1JDK8FeO"
      },
      "source": [
        "base_learning_rate=0.0005\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(base_learning_rate), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=['acc']\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Ha-Z8k8or6"
      },
      "source": [
        "epochs  = 100\n",
        "history_fine = model.fit(\n",
        "    train_batches, \n",
        "    initial_epoch=history.epoch[-1],\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=valid_batches,\n",
        "    validation_steps=val_steps,\n",
        "    epochs=epochs,\n",
        "     callbacks = callbacks_list \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzswMiCP3hDC"
      },
      "source": [
        "loss, acc = \\\n",
        "model.evaluate(test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ip-IXfFfZ5h"
      },
      "source": [
        "#THis is Part 2 Testing Saved Model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slBwQyuhhG-f"
      },
      "source": [
        "iresv2 = tf.keras.models.load_model('drive/MyDrive/Cancer Model/iresnetv2_fine.h5').get_layer('inception_resnet_v2')\n",
        "cmodel = tf.keras.models.load_model('drive/MyDrive/Cancer Model/iresnetv2_fine.h5', compile=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqbPcNVxhG-f",
        "outputId": "e5c07731-93f6-4832-fddb-328a48f2d637"
      },
      "source": [
        "model_builder = keras.applications.inception_resnet_v2.InceptionResNetV2\n",
        "img_size = (299, 299)\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "model = model_builder(weights=\"imagenet\", include_top=True, input_tensor=inputs)\n",
        "for layer, dense_layer in zip(model.layers[1:], iresv2.layers[1:]):\n",
        "    layer.set_weights(dense_layer.get_weights())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ks4tjQhG-f"
      },
      "source": [
        "img_size = (299, 299)\n",
        "preprocess_input = keras.applications.inception_resnet_v2.preprocess_input\n",
        "\n",
        "last_conv_layer_name = \"conv_7b\"\n",
        "classes=['nv','mel','bkl', 'bcc', 'akiec', 'vasc', 'df']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGifMVophG-g"
      },
      "source": [
        "image_size = 299\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAXu36CdhG-g",
        "outputId": "d3bf4dfd-b22e-4f36-b5f5-8b2b8a6091f2"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.inception_resnet_v2.preprocess_input)\n",
        "test_batches = datagen.flow_from_directory(\n",
        "    'drive/MyDrive/Cancer Model/val_dir',\n",
        "    target_size = (image_size,image_size),\n",
        "    batch_size = 1,\n",
        "    shuffle = False,\n",
        "    class_mode = 'sparse'\n",
        "    )\n",
        "cmodel.evaluate(test_batches,steps=828)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 828 images belonging to 7 classes.\n",
            "828/828 [==============================] - 449s 538ms/step - loss: 0.2703 - acc: 0.9239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27027857303619385, 0.9239130616188049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvO213GhKEx"
      },
      "source": [
        "#Part 3 visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPrbPJXdy1Ae"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Display\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T07TnKrZzMyy"
      },
      "source": [
        "#The Grad-CAM algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjUgJsBNzJ2g"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKpNG98YzXiG"
      },
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B37-_QAXdjB"
      },
      "source": [
        "cmodel = tf.keras.models.load_model('drive/MyDrive/Cancer Model/iresnetv2_fine.h5', compile=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pagXyWXRg965"
      },
      "source": [
        "iresv2 = tf.keras.models.load_model('drive/MyDrive/Cancer Model/iresnetv2_fine.h5').get_layer('inception_resnet_v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUGPox12wEXS",
        "outputId": "e5c07731-93f6-4832-fddb-328a48f2d637"
      },
      "source": [
        "model_builder = keras.applications.inception_resnet_v2.InceptionResNetV2\n",
        "img_size = (299, 299)\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "model = model_builder(weights=\"imagenet\", include_top=True, input_tensor=inputs)\n",
        "for layer, dense_layer in zip(model.layers[1:], iresv2.layers[1:]):\n",
        "    layer.set_weights(dense_layer.get_weights())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWe2ARk7yWbf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmLZJXXyyPAh"
      },
      "source": [
        "relu = model.get_layer(model.layers[-3].name)\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(relu.output)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(7)(x)\n",
        "model = tf.keras.models.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tb8-mdiRXeZv",
        "outputId": "925912d8-3286-4ecb-9ab4-0d8cecfc3ca9"
      },
      "source": [
        "ires = cmodel.layers[0]\n",
        "ires.layers[-3].name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'conv_7b'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi8znN0Iw1mU"
      },
      "source": [
        "img_size = (299, 299)\n",
        "preprocess_input = keras.applications.inception_resnet_v2.preprocess_input\n",
        "\n",
        "last_conv_layer_name = \"conv_7b\"\n",
        "classes=['nv','mel','bkl', 'bcc', 'akiec', 'vasc', 'df']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttJfX61fCc1L"
      },
      "source": [
        "image_size = 299\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQlV8q03iczo"
      },
      "source": [
        "\n",
        "# The local path to our target image\n",
        "img_path = \"drive/MyDrive/Cancer Model/val_dir/vasc/ISIC_0026490.jpg\"\n",
        "image = tf.keras.preprocessing.image.load_img(img_path)\n",
        "input_arr = keras.preprocessing.image.img_to_array(image, dtype='float32')\n",
        "input_arr = preprocess_input(input_arr)\n",
        "input_arr = tf.keras.preprocessing.image.smart_resize(input_arr, size=(299,299))\n",
        "\n",
        "#print(input_arr.shape)\n",
        "n = np.argmax(cmodel.predict(np.array([input_arr])))\n",
        "print(classes[n])\n",
        "Image(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3vVRF-rgE0g",
        "outputId": "8a8c96b7-dfc2-4a5c-fadc-25391c6aa661"
      },
      "source": [
        "cmodel.layers[0].inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 299, 299, 3) dtype=float32 (created by layer 'input_4')>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM37Xjo_b9E5"
      },
      "source": [
        "# Prepare image\n",
        "#img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "\n",
        "# Print what the top predicted class is\n",
        "\n",
        "#preds = np.argmax(cmodel.predict(np.array([input_arr])))\n",
        "print(\"Predicted:\", classes[n])\n",
        "model.layers[-1].activation = None\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0uK28Tgb87g"
      },
      "source": [
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWlw5of2Z9Oq"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}